# 附录B：上下文工程的演进历史与哲学思考

> **论文来源**：Context Engineering 2.0
> **论文链接**：https://arxiv.org/abs/2510.26493
> **参考资料**：https://hjfy.top/arxiv/2510.26493
> **核心理念**：上下文工程是一门关于熵减的古老学科

---

## 引言：一门关于熵减的古老学科

要理解上下文工程，必须先回答：**为什么人与机器的交流如此困难？**

### 认知鸿沟的本质

论文认为，**这是因为人类与机器之间，存在一道认知鸿沟。**

**人类的交流是高熵的**：
- 表达无序、混乱、充满隐含信息
- 例如："帮我搞定那个报告"
  - 需要记忆："那个报告"指什么？
  - 需要判断：从语气判断紧急程度
  - 需要理解：社交暗示和隐含期望
- 这些都是海量的、模糊的、非结构化的上下文

**机器是低熵生物**：
- 无法接受足够多的上下文
- 只能理解明确的、毫不含糊的指令
- 无法处理模糊性和隐含信息

### 上下文工程的本质

> **核心洞察**：为了弥合这道鸿沟，人类必须将"高熵"意图转化为机器可理解的"低熵"指令。其手段，就是建立更丰富有效的上下文。

正如马克思所说，**人的本质是社会关系的总和**。想要让AI更理解我们，就得让它理解人身处的一切情景。

**这就是上下文工程的本质，通过更好的上下文，达成系统性的熵减过程。**

### 核心定义

在这个系统中：
- **实体**：人、应用、环境（最重要的元素）
- **上下文**：描述实体状态的所有信息
- **上下文工程**：设计和优化上下文的收集、管理、使用，以提升机器理解和任务表现的努力

从这个意义上讲，**上下文工程根本不是新概念**。在AI之前，它已经发展了20多年，而现在，我们已经在**上下文工程2.0时代**了。

![上下文工程演进](https://mmbiz.qpic.cn/sz_mmbiz_png/ow6przZuPIHz8IhVSm6wibW4XDIaTJUhT6fmKIaRpdRbFsmxTicR0Ub8maJQhT91AA7ygseDGibwhZ88BjlBcMJvg/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1)

---

## 第一部分：历史演进

### 1.0时代（1990s-2020）：上下文即翻译

从计算机出现后，我们就开始探索人机理解的逻辑。**操作系统的UI就是最古老、最成功的上下文工程实践。**

#### 核心特征

**在那个时代，上下文工程的核心是翻译，即把人的自然语言意图，翻译成机器可理解的语言。**

#### 典型实践

- **图形界面（GUI）**：
  - 工程师通过设计图形界面
  - 用鼠标操作和结构化界面
  - 将高熵意图"工程化"为低熵交互流程

- **编程语言**：
  - 把自然语言框架化成规范指令
  - 提供确定性的语法和语义

![1.0时代](https://mmbiz.qpic.cn/sz_mmbiz_png/ow6przZuPIHz8IhVSm6wibW4XDIaTJUhTY0tEJk0oxsOpJIycwBKxDFialZWQs2ANialdF0ZNqqotVuqONUvNb8zQ/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1)

#### 核心问题

但这个过程其实**很违反人类的自然表达天性**：
- 学编程不光要学语言
- 还要学习一种规范化的思维
- 需要将人类的高熵思维转换为机器的低熵逻辑

---

### 2.0时代（2020-至今）：上下文即指令

#### 时代转折

2020年，随着GPT-3发布，我们迎来了一个全新时代。**用户可以直接用自然语言和机器对话。**

![2.0时代](https://mmbiz.qpic.cn/sz_mmbiz_png/ow6przZuPIHz8IhVSm6wibW4XDIaTJUhTdfQXBXMkde5W1YaYvaUc7o6Rm3FtAUiaU4a4AvLDvot3ibic8go71MicAg/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1)

#### 核心变化

- ✅ 翻译的中间层消失了
- ✅ 设计师和程序员的熵减工作随之消失
- ❌ 但普通用户发现：**AI依然理解不了话语背后的信息**

#### 熵减主体的转移

**熵减的需求并没有消失，只是转移到了用户身上**：
- 必须学会精确表达意图
- 构建有效的prompt
- 调试输出结果

#### 提示词工程的爆发

**这就是提示词工程爆发的原因**：人们在试图重新发明一种结构化的自然语言来减少沟通中的障碍。

#### 范式转变

但除了规范自己的表达，我们也可以从模型本身下手：

> **给它提供更好的脚手架和系统，让它更好地理解我们的意图。**

**这就是上下文工程诞生的背景。**

---

## 第二部分：AI的四大缺陷

既然上下文工程是为了解决目前人与AI沟通的Gap，那它做不到和我们人类一样可以高熵交流的核心原因都有什么呢？

论文通过与人类沟通做对比，总结了**八大AI的缺陷**，我们可以把它归结成**四种核心缺陷**。正是因为这些缺陷存在，它理解不了我们的高熵交流，造成了Gap。

### 缺陷一：感官残缺

**问题**：AI的感官是残缺的。

**对比人类**：
- 人类沟通时会接收大量文字外信息
- 表情、语气、肢体语言、环境氛围

**AI的局限**：
- 只能获得用户明确的输入
- 看不见我们所处的环境
- 上下文收集存在先天缺陷

### 缺陷二：理解能力有限

**问题**：AI的理解能力有限。

**深层矛盾**：
- 与人类相比，AI理解和整合上下文的能力很有限
- 就算感官不残缺，即使把所有信息都喂给AI，它也不一定理解其中关系

**具体表现**：
- 当前模型难以处理复杂逻辑
- 难以理解图像中的关系信息
- 缺乏常识推理能力

### 缺陷三：记忆缺失（最要命）

**问题**：记忆的缺失。

**根本原因**：
- **Transformer架构存在长上下文性能瓶颈**
- 导致模型既没有长期记忆系统
- 也难以捕捉长距离依赖关系

**影响**：
- AI记不住过去的对话
- 就不可能像人一样建立背景共识
- 正是这些"我们都知道的过去"，让人类说话如此省力

**当前方案的局限**：
- 试图去存储记忆的方法（如RAG等）
- 仍然效率较低

### 缺陷四：注意力涣散

**问题**：相对于人来讲，AI的注意力是涣散的。

**论文称之为**："上下文选择困难"

**具体场景**：
- 就算解决了记忆问题
- 给AI外挂了长期记忆（比如RAG）
- 理论上可以存储所有内容
- **但面对海量信息时，AI并不知道该看哪里**

### 提示词工程：上一代补丁

针对这些缺点，过去提示词工程的做法：
- 通过添加"前情提要"修补记忆缺失
- 通过手动精炼信息、规范化表达减少理解和注意力负担

> **它就是上一代针对模型缺陷的全面补丁。**

**但这个过程太耗费力气了。**

### 上下文工程的使命

> **因此一个好的上下文工程，就是尽可能搭建脚手架，让模型借助脚手架，解决当下能力不足的问题。**

**终极愿景**：
- 让AI真的可以成为人的数字存在（Digital Presence）
- 人们可通过上下文"数字永生"
- 让你的对话、决策、交互轨迹可以持续演化

---

## 第三部分：上下文工程的技术框架

### 整体架构：收集、管理、使用

为了解决模型当前问题，论文提出了一个包含**收集、管理、使用**三个阶段的完整上下文工程体系。

这张技术地图详细说明了我们为弥补LLM缺陷而必须搭建的庞大脚手架系统。

![技术框架](https://mmbiz.qpic.cn/sz_mmbiz_png/ow6przZuPIHz8IhVSm6wibW4XDIaTJUhTbteEu4s8M0GD4GH3L5vO9gRRUL8PnmXnW2Gibv6mqr0gdFD2BBDH4SA/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1)

---

### 构件一：上下文收集与记忆系统

**解决的缺陷**：AI的"感官残缺"与"记忆缺失"

#### 上下文收集

我们必须超越简单的文本输入，转向**多模态、分布式的收集**。

**1. 多模态融合**

将文本、图像、音频通过各自编码器映射到共享向量空间，让模型真正理解多模态意涵。

![多模态融合](https://mmbiz.qpic.cn/sz_mmbiz_png/ow6przZuPIHz8IhVSm6wibW4XDIaTJUhTFP6km54EoiabXSiaM1B0KPiaplJzuPMz7xwPTIcx1DRItD2dmnlt9MboQ/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1)

**2. 分布式收集**

通过以下设备主动捕捉用户无法用文字清楚表达的环境上下文和高熵信息：
- 智能手机
- 可穿戴设备
- IoT传感器
- 甚至脑机接口

![分布式收集](https://mmbiz.qpic.cn/sz_mmbiz_png/ow6przZuPIHz8IhVSm6wibW4XDIaTJUhTPjb1ISKzmvnIjxySrf3hbxNOEySADwurwz6chtVdTCljJEQbHqRUnA/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1)

#### 存储系统：给记忆搭建脚手架

**目标**：为了解决Transformer带来的记忆缺失，我们需要**构建分层内存架构，让模型形成类人的记忆结构。**

**类比操作系统的内存管理**：

| 层次 | 操作系统 | AI系统 | 特点 |
|------|---------|--------|------|
| 短期记忆 | 内存（RAM） | 上下文窗口 | 有限、快速访问 |
| 长期记忆 | 硬盘（HDD） | 外部数据库 | 持久化存储、高重要性上下文 |

**记忆转移机制**：
- 类似人类的睡眠过程
- 系统处理过往内容
- 将重要的短期记忆转存为长期记忆

---

### 构件二：上下文管理

**解决的缺陷**：AI理解能力有限，难以处理复杂逻辑和关系信息

#### 核心技术：上下文抽象（"自我烘焙"Self-Baking）

**理念**：
- 既然AI看不懂原始的、高熵的上下文
- 这个脚手架就充当预处理器
- 主动将上下文消化并烘焙成AI能理解的低熵结构

![自我烘焙](https://mmbiz.qpic.cn/sz_mmbiz_png/ow6przZuPIHz8IhVSm6wibW4XDIaTJUhTLhw36RWVYmMXXsBMDLS6f1xCKRyJB0j2yBz9SCNaTUJagMSMXoymmg/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1)

**关键洞察**：
> 这并非简单摘要，而是**区分记忆存储和学习的关键**。没有它，智能体只是在回忆；有了它，智能体才是在积累知识。

#### 三种实现方法（从简单到高级）

**1. 自然语言摘要**
- **方法**：让AI自己摘要重要信息
- **优势**：实现简单，易于理解
- **局限**：纯文本，缺少结构，难以深度推理

**2. 模式化提取**
- **方法**：从原始上下文提取关键事实
  - 人物、地点、事件
  - 按固定模式存入知识图谱
- **优势**：AI不再需要理解复杂关系，只需查询已准备好的结构化关系图
- **适用**：需要结构化知识的场景

**3. 在线蒸馏**
- **方法**：如Thinking Machine提出的方法
  - 将上下文渐进式压缩为向量
  - 转化成模型自己的知识
- **优势**：最高效的知识内化
- **挑战**：技术复杂度高

---

### 构件三：上下文使用

**解决的缺陷**：AI注意力涣散问题

**目标**：规范收集和管理后的上下文如何进行协作和推理。

#### 核心解决方案：高效的上下文选择机制

**当前问题**：
- 模型在RAG中搜索记忆时过于依赖语义相关性（向量搜索）
- 会搜出大量信息，导致上下文过载
- 理解能力大幅下降

**更高效的搜索机制需要满足的特质**：

**1. 理解逻辑依赖**
- 让AI使用RAG搜索时用逻辑关系
- 而不是简单地问"什么信息在语义上最像？"
- 考虑因果关系、时序关系、层级关系

**2. 平衡新近度与频率**
- 优先关注"最近使用过"的信息
- 或"经常使用"的信息
- 实现类似LRU（最近最少使用）的策略

**3. 主动需求推断（终极目标）**
- 系统不再被动地等待你提问
- 基于上下文，对你隐藏目标做分析
- 主动推断你下一步可能需要什么信息
- 并提前为你准备好

#### 闭环工作流程

至此，这个上下文工程框架通过**收集、管理、使用**上下文，弥补了AI在"感官"、"理解"、"记忆"和"注意力"上的四大缺陷，形成了一整套关于上下文的闭环工作流程。

> **在这个流程下，我们可以把提示词工程的重担转移回模型自身，让它通过系统尽可能好地理解我们。**

---

## 第四部分：未来展望

### 上下文工程3.0时代

**时间预测**：当机器智能达到人类水平

**核心能力**：
- 能处理情绪、暗示等复杂上下文模态
- 理解瓶颈将被打破
- 记忆处理将成熟
- AI将主动理解我们的"场景"并与我们协作

**仍存在的局限**：
- 长期记忆问题仍未完全解决
- 模型主动性依然有限

![未来演进](https://mmbiz.qpic.cn/sz_mmbiz_png/ow6przZuPIHz8IhVSm6wibW4XDIaTJUhTnU9lT9TvibHScAOPZOGDzdicx668Xo2Ou2Hw1Ee1TtyKibM4wFkXMa1hg/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1)

---

### 上下文工程4.0时代

**时间预测**：当机器智能达到"超人智能"

**核心特征**：
- 人机交流的熵被彻底消除
- 你什么都不用说，它都能预测你想干什么并执行安排
- 完全理解隐含意图和潜在需求

**终极形态**：

> **在这个时代，上下文工程消失了。**
>
> **或者用更好的方法讲，它所搭建的脚手架最终融入了核心架构。**

---

## 第五部分：脚手架的归宿

### 技术演进的常态

**这在技术发展的历史中，几乎是常态。**

#### 案例：注意力机制的演变

**起源**：
- 最初作为编码器-解码器RNN的"外挂补丁"出现
- 用来解决序列翻译中的瓶颈问题

**演变**：
- 2017年，Transformer架构彻底将注意力机制内化为核心
- 只是移除了RNN部分以实现并行处理

**结果**：
- **曾经的脚手架，变成了今天所有大语言模型的基础架构**

---

### 上下文工程的当前演进

**同样的故事，在上下文工程领域其实也在进行中。**

#### MCP的标准化

**里程碑事件**：
- 2025年3月，Sam Altman宣布将在所有OpenAI产品中添加MCP支持
- 包括ChatGPT桌面应用

**意义**：
- 这标志着工具使用这个能力，不再是简单的"外挂"
- 而是正在成为Agent架构的固定组成部分

---

### 演进模式的总结

从注意力机制到MCP，我们看到了同一个模式：

> **当某种脚手架被证明足够有效且通用时，它就会从外部工具演变为标准协议，最终融入模型或Agent的核心架构。**

---

## 结语：脚手架的终极形态

### 当下的必要性

因此，即使我们知道上下文工程有一天会消失，但当下，**它依然是通往AGI路上的必经之路**。

**不是因为**：它能让模型"更聪明"（那是算法和算力的任务）

**而是因为**：它能让模型"更好用"

### 历史的经验

> **正如Transformer不需要等到模型完全理解语言才出现，MCP也不需要等到模型拥有完美记忆才部署。它们的存在，让我们可以用今天的模型，实现明天才能达到的应用体验。**

### 未来的归宿

这些脚手架，最终会以某种形式融入未来的模型：
- 也许是协议
- 也许是架构
- 也许是全新的神经网络层

**它们不会消失，只会invisible（隐形化）。**

---

## 核心洞察

> **上下文工程的终极形态，就是让自己成为不需要被谈论的基础设施。**

---

**文档版本**：v1.0
**整理日期**：2025年12月
**论文来源**：Context Engineering 2.0 (arXiv:2510.26493)
**整理说明**：本文档基于原论文解读整理，保留了所有图片和核心观点，调整了结构以提高可读性。重点突出了"熵减"理论和"脚手架"隐喻两大核心概念。
