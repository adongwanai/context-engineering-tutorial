# 第2章：核心原理 - 为什么Context有效？

> **学习目标**：
> - 理解Transformer的Self-Attention机制
> - 掌握In-Context Learning（上下文学习）的工作原理
> - 认识"Lost in the Middle"现象及其工程影响

---

## 2.1 Attention机制：上下文窗口的物理基础

（待撰写）

## 2.2 Few-Shot学习：模型如何在不更新权重的情况下"学会"新任务

（待撰写）

## 2.3 示例的作用：格式 vs 内容的反直觉结论

（待撰写）

## 2.4 长文本陷阱：中间迷失现象与Re-ranking策略

（待撰写）

---

## 参考资源

- Attention Is All You Need
- Language Models are Few-Shot Learners (GPT-3)
- Lost in the Middle: How LLMs Use Long Contexts

---

**上一章**：[第1章：什么是上下文工程？](./chapter01-what-is-context-engineering.md)  
**下一章**：[第3章：上下文失败模式与诊断](./chapter03-context-failure-patterns.md)



